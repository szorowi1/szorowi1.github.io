---
title: "Month of May, Paper a Day - Day 01"
layout: post
date: 2020-05-01 00:00
tag:
  - paper
headerImage: false
description: ""
category: blog
author: szoro
externalLink: true
math: false
---

Today, I read [Fried (2020)](https://osf.io/6cts9/), *Lack of theory building and testing impedes progress in the factor and network literature*. As the title suggests, the paper spells out a number of ways in which a lack of robust theory precludes advancements in factor/network modeling approaches to understanding psychological processes (e.g. personality, psychopathology). I won't attempt to weigh in on the central thesis of paper, but instead apply some of its (many) insights to computational psychiatry and reinforcement learning.

In order to understand how a lack of theory impedes progress, we first need to delineate what constitutes a *weak* and *strong* theory. Fried defines weak theories as,

> narrative and imprecise accounts of hypotheses, vulnerable to hidden assumptions and other unknowns. They do not spell out the **functional form** in which two variables relate to each other, the conditions under which a hypothesized effect should occur, or the magnitude of a proposed effect.

In contrast, strong theories,

> explicate a precise set of assumptions and axioms about a phenomenon non-ambiguously... often by representing the theory as a formal model, using mathematical notation.

Strong theories make clear predictions and facilitate *severe tests*. Strong theories also allow for predictions even in the absence of previous observation.

By formally expressing the assumptions and functional form of a theory, statistical models facilitate -- but are not isomorphic -- strong theory. This is where the trouble begins, as Fried notes: in the absence of strong theory, "statistical models are often [incorrectly] interpreted as theoretical models, [such that] latent variables are often conflated with psychological constructs." That is, the tools of strong theory are mistaken for strong theory itself. For many reasons (two of which are discussed below), statistical models on their own can only offer *effects in need of explaining*, not explanations in themselves.

Before moving onto issues with statistical models *in vacuo*, I just want to note how remarkably similar this issue in factor/network theory is to reinforcement learning theory. At one point, Fried comments:

> Researchers in the network literature have at times used the terms “network approach” or “network framework” ambiguously, i.e. without denoting if they mean theory or statistics.

This sentence would be equally true if one were to replace "network" with "reinforcement learning". In the literature, reinforcement learning is sometimes described as a normative theoretical framework for understanding decision making and learning [(Niv, 2009)](http://dx.doi.org/10.1016/j.jmp.2008.12.005), and elsewhere described as a statistical/machine learning framework [(Wikipedia)](https://en.wikipedia.org/wiki/Reinforcement_learning). Of course, the truth is that it is both: it is a framework that can *explain* behavior when paired with psychoneurobiological theory but also simply *predict* behavior as an algorithm for learning policies in response to feedback. This strongly suggests then that we should find similar problems in the reinforcement learning literature as Fried notes in the factor/network modeling literature, namely treating latent variables (i.e. model parameters) as explanatory in their own right. (I will give some examples of such below.)

One issue with statistical models in isolation, Fried notes, is statistical equivalence. That is, two or more statistical models -- with radically different parameterizations -- may yield similarly excellent fits to the data. In such an event, we have learned little about the underlying generating mechanisms of behavior. This is a frequent occurrence in reinforcement learning, where model spaces are highly correlated. (This is not in itself surprising given the impoverished nature of choice data as a dependent variable.) As such, model comparison is not enough. We need strong theory that yield *severe tests*, or behavioral predictions that are falsifiable.

A second issue with statistical modes in isolation is, as he puts, an illusion of explanation: differences in model accuracies or model parameters (e.g. between two groups) "give the false impression that there is a psychological explanation, whereas the actual explanation is purely statistical". One example of this in reinforcement learning is the number of papers reporting differences in learning rates between healthy and anxious individuals. The problem here is that learning rates can be a function of a great many things (e.g. expectations about environmental volatility, asymmetric weighting of rewards/punishments, capturing unmodeled choice autocorrelation or decay). Differences in model parameters, devoid of meaningful interpretation and validation of what those parameters capture, do not provide an explanation with respect to psychological processing.

This paper then offers some useful insights for computational psychiatry. Even with sophisticated modeling, we should not expect rapid progress without strong theory leading the way.
